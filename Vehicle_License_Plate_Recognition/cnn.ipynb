{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape:0\", shape=(48, 24, 1), dtype=uint8)\n",
      "100\n",
      "Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#创建一个reader来读取TFRecord文件中的样例\n",
    "reader = tf.TFRecordReader()\n",
    "# filename = tf.train.string_input_producer(['car_train.tfrecords'])\n",
    "filename = tf.train.string_input_producer(['car_validation.tfrecords'])\n",
    "#从文件中读取一个样例\n",
    "_, one_example = reader.read(filename)\n",
    "#解析读入的数据\n",
    "features = tf.parse_single_example(one_example,features={\n",
    "    'labels':tf.FixedLenFeature([], tf.int64),\n",
    "    'image_raw':tf.FixedLenFeature([], tf.string),\n",
    "    'img_width':tf.FixedLenFeature([], tf.int64),\n",
    "    'img_high':tf.FixedLenFeature([], tf.int64)\n",
    "})\n",
    "#将字符串解析成图像对应的像素数组\n",
    "images = tf.decode_raw(features['image_raw'], tf.uint8)\n",
    "images = tf.reshape(images, [48, 24, 1])\n",
    "print(images)\n",
    "labels = tf.cast(features['labels'], tf.int32)\n",
    "widths = tf.cast(features['img_width'], tf.int32)\n",
    "highs = tf.cast(features['img_high'], tf.int32)\n",
    "\n",
    "images_bath, labels_bath = tf.train.shuffle_batch([images, labels], batch_size = 100, capacity = 4000, \n",
    "                                                  min_after_dequeue = 3888, \n",
    "                                                  num_threads = 2,\n",
    "                                                  shapes = ([48,24,1],[]))\n",
    "print(labels_bath.shape[0])\n",
    "print(labels_bath[2])\n",
    "# with tf.Session() as sess:\n",
    "#     #启动多线程\n",
    "#     sess.run(init)\n",
    "#     sess.run(tf.local_variables_initializer())\n",
    "#     coord = tf.train.Coordinator()\n",
    "#     threads = tf.train.start_queue_runners(sess=sess, coord = coord)\n",
    "#     for i in range(1,10):\n",
    "#         image, label = sess.run([images_bath, labels_bath])\n",
    "#         print(image.shape)\n",
    "# #         print(highs, widths)\n",
    "#         for i in range(1,100):\n",
    "#             plt.imshow(image[i].reshape(48, 24), cmap = 'gray')\n",
    "#             plt.show()\n",
    "#     coord.request_stop()\n",
    "#     coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./cnn_txt/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./cnn_txt/model.ckpt\n",
      "epoch: 0 ,accuracy is: 0.98 ,loss is : 10.5746\n",
      "epoch: 10 ,accuracy is: 0.98 ,loss is : 6.97541\n",
      "epoch: 20 ,accuracy is: 0.99 ,loss is : 5.94238\n",
      "epoch: 30 ,accuracy is: 1 ,loss is : 2.99004\n",
      "epoch: 40 ,accuracy is: 0.99 ,loss is : 5.98825\n",
      "epoch: 50 ,accuracy is: 1 ,loss is : 3.37849\n",
      "epoch: 60 ,accuracy is: 0.97 ,loss is : 8.93692\n",
      "epoch: 70 ,accuracy is: 0.98 ,loss is : 6.4889\n",
      "epoch: 80 ,accuracy is: 0.98 ,loss is : 13.5032\n",
      "epoch: 90 ,accuracy is: 0.98 ,loss is : 5.33281\n",
      "acc_finally: 0.9894\n"
     ]
    }
   ],
   "source": [
    "acc_num = 0\n",
    "acc_fin = 0\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "def hot(x):\n",
    "    a = np.zeros([x.shape[0],34])\n",
    "    for i in range(x.shape[0]):\n",
    "        a[i][x[i]-1] = 1\n",
    "    return a\n",
    "\n",
    "\n",
    "# Input layer\n",
    "X = tf.placeholder(tf.float32, [None, 48, 24, 1])\n",
    "Y = tf.placeholder(tf.float32, [None, 34])\n",
    "# Layer 1\n",
    "W1 = tf.Variable(tf.truncated_normal([5, 5, 1, 90], stddev = 0.1))\n",
    "b1 = tf.Variable(tf.constant(0.0, shape=[90]))\n",
    "conv1 = tf.nn.conv2d(X, W1, strides = [1,1,1,1], padding = 'VALID')\n",
    "tanh1 = tf.nn.tanh(tf.nn.bias_add(conv1,b1))\n",
    "# Layer 2\n",
    "pool1=tf.nn.max_pool(tanh1,ksize=[1,2,2,1],strides=[1,2,2,1],padding = \"SAME\")\n",
    "# layer 3\n",
    "W2 = tf.Variable(tf.truncated_normal([5, 5, 90, 60], stddev = 0.1))\n",
    "b2 = tf.Variable(tf.constant(0.0, shape=[60]))\n",
    "conv2 = tf.nn.conv2d(pool1, W2, strides = [1,1,1,1], padding = \"VALID\")\n",
    "tanh2 = tf.nn.tanh(tf.nn.bias_add(conv2,b2))\n",
    "# layer 4\n",
    "pool2=tf.nn.max_pool(tanh2,ksize=[1,3,3,1],strides=[1,3,3,1],padding = \"SAME\")\n",
    "pool_size = tf.shape(pool2)\n",
    "reshape = tf.reshape(pool2,[pool_size[0],-1])\n",
    "# layer 5\n",
    "fc1_weight = tf.Variable(tf.truncated_normal([720,300],stddev = 0.1))\n",
    "fc1_bias=tf.Variable(tf.constant(0.0,shape=[300]))\n",
    "fc1 = tf.nn.tanh(tf.matmul(reshape,fc1_weight)+fc1_bias)\n",
    "# layer 6\n",
    "fc2_weight = tf.Variable(tf.truncated_normal([300,34], stddev = 0.1))\n",
    "fc2_bias=tf.Variable(tf.constant(0.0, shape=[34]))\n",
    "fc2 = tf.nn.softmax(tf.matmul(fc1, fc2_weight)+fc2_bias)\n",
    "#cross function\n",
    "cross_entropy = - tf.reduce_sum(Y * tf.log(fc2))\n",
    "is_correct = tf.equal(tf.argmax(fc2, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "# optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train_step = optimizer.minimize(cross_entropy)\n",
    "\n",
    "# saver\n",
    "cnn_txt = \"./cnn_txt\"\n",
    "if not os.path.exists(cnn_txt):\n",
    "    os.makedirs(cnn_txt)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    #启动多线程\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord = coord)\n",
    "    txt = tf.train.get_checkpoint_state(cnn_txt)\n",
    "    if txt and txt.model_checkpoint_path:\n",
    "        print(txt.model_checkpoint_path)\n",
    "        saver.restore(sess, txt.model_checkpoint_path)\n",
    "    for epoch in range(100):\n",
    "        # Load the input data\n",
    "        image, label = sess.run([images_bath, labels_bath])\n",
    "        train_data = {X: image, Y: hot(label)}\n",
    "        # Train\n",
    "        sess.run(train_step, feed_dict = train_data)\n",
    "\n",
    "        # Accuracy on training data\n",
    "        acc, loss = sess.run([accuracy, cross_entropy], feed_dict = train_data)\n",
    "        acc_num = acc*100 + acc_num\n",
    "#         # Trying it out on test data\n",
    "#         test_data = {X: mnist_data.test.images, Y_: mnist_data.test.labels}\n",
    "\n",
    "#         # Accuracy on test data\n",
    "#         acc_test, loss_test = sess.run([accuracy, cross_entropy], feed_dict = test_data)\n",
    "#         saver.save(sess,cnn_txt + \"/model.ckpt\")\n",
    "        if epoch % 10 ==0:\n",
    "            print(\"epoch: %d ,accuracy is: %g ,loss is : %g\" % (epoch, acc, loss))\n",
    "    acc_fin = acc_num/10000\n",
    "    print(\"acc_finally: %g\" % acc_fin)\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
